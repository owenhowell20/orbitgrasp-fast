import os
import sys
import time

file_dir = os.path.dirname(__file__)
sys.path.append(file_dir)
sys.path.append('..')
import numpy as np
from pathlib import Path
import torch
import pybullet
from grasp import Label

import btsim
from workspace_lines import workspace_lines
from utils.transform import Rotation, Transform
from scipy.spatial.transform import Slerp
from segment_anything import SamAutomaticMaskGenerator, build_sam
from simulator import camera
import utils.utils_3d as utils_3d
from sam3d import filter_masks, get_mask_rgb


class ClutterRemovalSim(object):
    def __init__(self, scene, object_set, gui=True, seed=None, rand=False, load_sam=False,n_intervals=36):
        assert scene in ["pile", "packed", "obj", "egad"]
        self.urdf_root = Path(f"{os.path.abspath(os.path.dirname(__file__))}/data_robot/urdfs/")

        self.scene = scene
        self.object_set = f'{scene}/{object_set}'
        # get the list of urdf files or obj files
        self.discover_objects()
        self.rand = rand
        self.global_scaling = {
            "blocks": 1.67,
            "google": 0.7,
            'google_pile': 0.7,
            'google_packed': 0.7,
        }.get(object_set, 1.0)

        self.random_rotations_limit = np.pi * 2.0
        self.n_intervals = n_intervals
        self.mask_generator = None
        self.colormaps, self.heightmaps, self.segmaps, self.maskmaps, self.maskrgbmaps = None, None, None, None, None
        self.pcds_xyz, self.pcds_rgb, self.pcds_masks = None, None, None

        self.gui = gui
        self.rng = np.random.RandomState(seed) if seed else np.random
        self.world = btsim.BtWorld(self.gui)

        self.size = 0.30
        # self.camera = self.world.add_camera(intrinsic, 0.1, 2.0)
        self.camera = self.world.add_camera()
        self.cams_config = camera.RealSenseD415.CONFIG
        X_center = 0.15
        Y_center = 0.15
        Z = 0.05
        self.workspace = np.asarray([[X_center - self.size / 2, X_center + self.size / 2],
                                     [Y_center - self.size / 2, Y_center + self.size / 2],
                                     [Z, Z + self.size]])

        if load_sam:
            self.loadSAM()
        self.bound_radio = 2 if scene == "pile" else 1.5

    @property
    def num_objects(self):
        return max(0, self.world.p.getNumBodies() - 2)  # remove table and the gripper from body count

    def loadSAM(self, pretrain_name='pretrained/sam_vit_h_4b8939.pth', cuda_device='cuda:0'):
        self.sam_checkpoint_path = Path.cwd().parent / pretrain_name
        self.mask_generator = SamAutomaticMaskGenerator(
            build_sam(checkpoint=self.sam_checkpoint_path).to(device=cuda_device))

    def discover_objects(self):
        root = self.urdf_root / self.object_set
        self.object_urdfs = [f for f in root.iterdir() if f.suffix == ".urdf"]
        # self.object_urdfs = self.object_urdfs[:200]
        # print(self.object_urdfs)

    def save_state(self):
        self._snapshot_id = self.world.save_state()

    def restore_state(self):
        self.world.restore_state(self._snapshot_id)

    def reset(self, object_count, index=None, color_=None, pose_=None, from_save=False):
        self.heightmaps, self.colormaps, self.segmaps = None, None, None
        self.maskmaps, self.maskrgbmaps = None, None
        self.pcds_xyz, self.pcds_rgb, self.pcds_masks = None, None, None
        self.world.reset()
        self.world.set_gravity([0.0, 0.0, -9.81])
        self.draw_workspace()
        # self.world.p.configureDebugVisualizer(self.world.p.COV_ENABLE_GUI, 0)
        if self.gui:
            self.world.p.resetDebugVisualizerCamera(
                cameraDistance=1.0,
                cameraYaw=0.0,
                cameraPitch=-45,
                cameraTargetPosition=[0.15, 0.50, -0.3],
            )

        table_height = 0.05
        self.place_table(table_height)
        self.gripper = Gripper(self.world)

        indexes, pose_list, color_list = list(), list(), list()
        if self.scene == "pile":
            if from_save:
                self.generate_pile_scene_from_save(index=index, pose_=pose_, color_=color_, table_height=table_height)
            else:
                indexes, pose_list, color_list = self.generate_pile_scene(object_count, table_height)
        elif self.scene == "packed":
            if from_save:
                self.generate_packed_scene_from_save(index=index, pose_=pose_, color_=color_)
            else:
                indexes, pose_list, color_list = self.generate_packed_scene(object_count, table_height)

        else:
            raise ValueError("Invalid scene argument")

        # check validity
        self.remove_and_wait(timeout=3)
        self.getObservation()
        if index is None:
            return indexes, pose_list, color_list

    def draw_workspace(self):
        points = workspace_lines(self.size)
        color = [0.5, 0.5, 0.5]
        for i in range(0, len(points), 2):
            self.world.p.addUserDebugLine(
                lineFromXYZ=points[i], lineToXYZ=points[i + 1], lineColorRGB=color
            )

    def place_table(self, height):
        urdf = self.urdf_root / "setup" / "plane.urdf"
        pose = Transform(Rotation.identity(), [0.15, 0.15, height])
        self.world.load_urdf(urdf, pose, scale=0.6, env_obj=True)

    def generate_pile_scene(self, object_count, table_height, index=None):
        # place box
        urdf = self.urdf_root / "setup" / "box.urdf"
        pose = Transform(Rotation.identity(), np.r_[0.02, 0.02, table_height])
        box = self.world.load_urdf(urdf, pose, scale=1.3, env_obj=True)
        # drop objects
        if index is not None:
            urdfs = [self.object_urdfs[index]]
        else:
            index = self.rng.choice(len(self.object_urdfs), size=object_count)
            urdfs = [self.object_urdfs[idx] for idx in index]
        # print(urdfs)

        pose_list = list()
        color_list = list()

        for i, urdf in enumerate(urdfs):
            if self.rand:
                rotation = Rotation.random(random_state=self.rng)
            else:
                rotation = Rotation.from_matrix(np.array([[1, 0, 0],
                                                          [0, 1, 0],
                                                          [0, 0, 1]]))

            xy = self.rng.uniform(1.0 / 3.0 * self.size, 2.0 / 3.0 * self.size, 2)
            scale = self.rng.uniform(0.8, 1.0)
            pose = Transform(rotation, np.r_[xy, table_height + 0.2], scale=scale)

            _, color = self.world.load_urdf(urdf, pose, scale=self.global_scaling * scale, return_color=True)

            color_list.append(color)
            pose_list.append(pose)

            self.wait_for_objects_to_rest(timeout=2.0)
        # remove box
        self.world.p.removeBody(box.uid)
        self.remove_and_wait()
        return index, pose_list, color_list

    def generate_pile_scene_from_save(self, index=None, pose_=None, color_=None, table_height=0.3):
        """
        Generate the scene from the saved state
        """
        urdf = self.urdf_root / "setup" / "box.urdf"
        pose = Transform(Rotation.identity(), np.r_[0.02, 0.02, table_height])
        box = self.world.load_urdf(urdf, pose, scale=1.3, env_obj=True)

        urdfs = [self.object_urdfs[idx] for idx in index]
        for i, urdf in enumerate(urdfs):
            scale = pose_[i].scale
            self.world.load_urdf(urdf, pose_[i], scale=self.global_scaling * scale, color=color_[i])

            self.wait_for_objects_to_rest(timeout=2.0)
        self.world.p.removeBody(box.uid)
        self.remove_and_wait()

    def generate_packed_scene(self, object_count, table_height):
        attempts = 0
        max_attempts = 12
        pose_list = list()
        color_list = list()
        index_list = list()
        while self.num_objects < object_count and attempts < max_attempts:
            self.save_state()
            index = self.rng.choice(len(self.object_urdfs))
            urdf = self.object_urdfs[index]

            x = self.rng.uniform(0.08, 0.22)
            y = self.rng.uniform(0.08, 0.22)
            z = 1.0
            angle = self.rng.uniform(0.0, 2.0 * np.pi)
            rotation = Rotation.from_rotvec(angle * np.r_[0.0, 0.0, 1.0])
            pose = Transform(rotation, np.r_[x, y, z])
            scale = self.rng.uniform(0.7, 0.8)
            body, color = self.world.load_urdf(urdf, pose, scale=self.global_scaling * scale, return_color=True)
            lower, upper = self.world.p.getAABB(body.uid)
            z = table_height + 0.5 * (upper[2] - lower[2]) + 0.002
            final_pose = Transform(rotation, np.r_[x, y, z], scale=scale)
            body.set_pose(pose=final_pose)
            self.world.step()

            if self.world.p.getContactPoints(body.uid):
                self.world.remove_body(body)
                self.restore_state()
            else:
                self.remove_and_wait()

            pose_list.append(final_pose)
            color_list.append(color)
            index_list.append(index)
            attempts += 1
        return index_list, pose_list, color_list

    def generate_packed_scene_from_save(self, index=None, pose_=None, color_=None):
        for i, idx in enumerate(index):
            self.save_state()
            urdf = self.object_urdfs[idx]

            pose = pose_[i]
            color = color_[i]
            scale = pose.scale
            trans = pose.translation.copy()
            trans[2] = 1.0
            new_pose = Transform(pose.rotation, trans)

            body = self.world.load_urdf(urdf, new_pose, scale=self.global_scaling * scale, color=color)

            body.set_pose(pose=pose)
            self.world.step()

            if self.world.p.getContactPoints(body.uid):
                self.world.remove_body(body)
                self.restore_state()
            else:
                self.remove_and_wait()

    def advance_sim(self, frames):
        for _ in range(frames):
            self.world.step()

    def execute_grasp_fast(self, action, remove=True, allow_contact=True, waitTime=2.0):
        pos, rot_q = action

        grasp_pose = Transform(Rotation.from_quat(rot_q), pos)
        T_world_grasp = grasp_pose
        T_grasp_pregrasp = Transform(Rotation.identity(), [0.0, 0.0, -0.05])
        T_world_pregrasp = T_world_grasp * T_grasp_pregrasp

        approach = T_world_grasp.rotation.as_matrix()[:, 2]
        angle = np.arccos(np.dot(approach, np.r_[0.0, 0.0, -1.0]))
        if angle > np.pi / 3.0:
            # side grasp, lift the object after establishing a grasp
            T_grasp_pregrasp_world = Transform(Rotation.identity(), [0.0, 0.0, 0.1])
            T_world_retreat = T_grasp_pregrasp_world * T_world_grasp
        else:
            T_grasp_retreat = Transform(Rotation.identity(), [0.0, 0.0, -0.1])
            T_world_retreat = T_world_grasp * T_grasp_retreat

        self.gripper.reset()
        self.gripper.set_tcp(T_world_pregrasp)
        self.world.step()
        if self.gripper.detect_contact():
            result = Label.FAILURE, self.gripper.max_opening_width, 'pregrasp'
            self.gripper.holding_obj = None
            self.gripper.move_home()
        else:
            self.gripper.move_tcp_xyz(T_world_grasp, abort_on_contact=False)
            if self.gripper.detect_contact() and not allow_contact:
                result = Label.FAILURE, self.gripper.max_opening_width, 'grasp'
                self.gripper.holding_obj = None
                self.gripper.move_home()
            else:
                self.gripper.move(0.0)
                self.gripper.move_tcp_xyz(T_world_retreat, abort_on_contact=False)
                if self.check_success(self.gripper):
                    result = Label.SUCCESS, self.gripper.read(), 'success'
                    if remove:
                        contacts = self.world.get_contacts(self.gripper.body)
                        self.world.remove_body(contacts[0].bodyB)
                else:
                    result = Label.FAILURE, self.gripper.max_opening_width, 'after'
                self.gripper.move_home()
                self.world.step()
        self.wait_for_objects_to_rest(waitTime)
        if remove:
            self.remove_and_wait()
        return result

    def _random_rotations(self):
        """
        Divide rotation radius into n intervals and randomly pick one from each interval.
        Args:
            n_intervals: Number of intervals to divide into

        Returns:
        A list containing a randomly chosen degree from each interval.

        """
        interval_size = self.random_rotations_limit / self.n_intervals
        intervals = [(i * interval_size, (i + 1) * interval_size) for i in range(self.n_intervals)]

        rotation_list = [self.rng.uniform(start, end) for start, end in intervals]

        return np.asarray(rotation_list)

    def rotation_matrix_from_vectors(self, vec1, vec2):
        """ Find the rotation matrix that aligns vec1 to vec2
        :param vec1: A 3d "source" vector
        :param vec2: A 3d "destination" vector
        :return mat: A transform matrix (3x3) which when applied to vec1, aligns it with vec2.
        """
        cross_product = lambda x, y: np.cross(x, y)
        a, b = vec1 / np.linalg.norm(vec1), vec2 / np.linalg.norm(vec2)
        v = cross_product(a, b)
        c = np.dot(a, b)
        s = np.linalg.norm(v)
        if s == 0:  # special case where vectors are parallel or anti-parallel
            if c == 1:
                return Rotation.from_matrix(np.eye(3))  # No rotation needed
            else:
                # 180 degree rotation around any axis perpendicular to vec1
                # Here we choose an axis perpendicular to the maximum component of vec1 for stability
                if abs(a[0]) > abs(a[1]):
                    # x component is larger, choose y axis for rotation to be more stable
                    axis = np.array([0, 1, 0])
                else:
                    # y component is larger or equal, choose x axis for rotation
                    axis = np.array([1, 0, 0])
                rotation_matrix = np.array([
                    [-1, 0, 0],
                    [0, -1, 0],
                    [0, 0, 1]
                ]) if np.allclose(axis, a) else np.array([
                    [-1, 0, 0],
                    [0, 1, 0],
                    [0, 0, -1]
                ])
                return Rotation.from_matrix(rotation_matrix)
        kmat = np.array([[0, -v[2], v[1]], [v[2], 0, -v[0]], [-v[1], v[0], 0]])
        rotation_matrix = np.eye(3) + kmat + kmat.dot(kmat) * ((1 - c) / (s ** 2))
        return Rotation.from_matrix(rotation_matrix)

    def sample_rotations_around_normal(self, normal, gripper_normal=(0, 1, 0)):
        if isinstance(normal, torch.Tensor):
            normal = normal.cpu().numpy()

        # Align the gripper direction to the normal
        rotation_align_gripper_to_normal = self.rotation_matrix_from_vectors(gripper_normal, normal)

        # Generate a series of rotations around the Z axis
        angles_degrees = self._random_rotations()

        rotations = [Rotation.from_rotvec(
            normal * angle) * rotation_align_gripper_to_normal for angle in
                     angles_degrees]

        return rotations, angles_degrees

    def mask_random_actions(self, pcd, sample_strategy, m=20, n_intervals=None, z_thresh=0.051):
        if n_intervals is not None:
            self.n_intervals = n_intervals

        pos = np.asarray(pcd.points)
        normals = np.asarray(pcd.normals)

        actions_list = list()
        points_list = list()
        normals_list = list()

        farthest_pts, index_list = sample_strategy(pos, normals, m, z_thresh)

        for index in index_list:

            point = pos[index]
            normal = normals[index]

            points_list.append(point)
            normals_list.append(normal)
            rotation_list, planar_rotation_list = self.sample_rotations_around_normal(normal)

            actions_for_point = list()
            for rotation, planar_rotation in zip(rotation_list, planar_rotation_list):
                action = np.concatenate([point, [planar_rotation], rotation.as_quat()])
                actions_for_point.append(action)

            actions_list.append(np.array(actions_for_point))
        return np.array(actions_list), np.array(points_list), np.array(normals_list), np.array(index_list)

    def mask_all_actions(self, pcd_points, pcd_normals, n_intervals=None, z_thresh=0.052):
        if n_intervals is not None:
            self.n_intervals = n_intervals

        device = pcd_points.device
        actions_list = list()

        indices = torch.where(pcd_points[:, 2] > z_thresh)[0]

        if len(indices) == 0:
            return None, None, None, None

        norms = torch.norm(pcd_normals[indices], dim=1, keepdim=True)
        norms = torch.where(norms == 0, torch.ones_like(norms, device=device), norms)
        normals_normalized = pcd_normals[indices] / norms

        for i, index in enumerate(indices):
            point = pcd_points[index]
            normal = normals_normalized[i]

            rotation_list, rotation_degrees = self.sample_rotations_around_normal(normal)

            actions_for_point = [torch.cat([point, torch.tensor([planar_rotation], device=device, requires_grad=False),
                                            torch.tensor(rotation.as_quat(), device=device, requires_grad=False)])
                                 for rotation, planar_rotation in zip(rotation_list, rotation_degrees)]

            actions_list.append(torch.stack(actions_for_point))
        # (m, n_intervals, 8), (m,3), (m,3)
        return torch.stack(actions_list).to(device), pcd_points[indices].to(device), pcd_normals[indices].to(
            device), indices

    def mask_all_actions_batch(self, pcd_points, pcd_normals, n_intervals=None, z_thresh=0.052):
        if n_intervals is not None:
            self.n_intervals = n_intervals

        device = pcd_points.device
        actions_list = list()

        indices = torch.where(pcd_points[:, 2] > z_thresh)[0]

        if len(indices) == 0:
            return None, None, None, None

        norms = torch.norm(pcd_normals[indices], dim=1, keepdim=True)
        norms = torch.where(norms == 0, torch.ones_like(norms, device=device), norms)
        normals_normalized = pcd_normals[indices] / norms

        # Generate all rotations and planar rotations in a batch
        rotations, planar_rotations = zip(
            *[self.sample_rotations_around_normal_batch(normal) for normal in normals_normalized])

        # Concatenate rotations and planar rotations for batch processing
        rotations = [torch.tensor([rotation.as_quat() for rotation in rotation_set], device=device) for rotation_set in
                     rotations]
        planar_rotations = torch.tensor(planar_rotations, device=device)

        # Create actions for all points in batch
        points_expanded = pcd_points[indices].unsqueeze(1).expand(-1, self.n_intervals, -1)
        planar_rotations_expanded = planar_rotations.unsqueeze(2).expand(-1, -1, 1)
        rotations_expanded = torch.stack(rotations).to(device)

        actions_for_points = torch.cat([points_expanded, planar_rotations_expanded, rotations_expanded], dim=2)

        return actions_for_points, pcd_points[indices].to(device), pcd_normals[indices].to(device), indices

    def sample_rotations_around_normal_batch(self, normal, gripper_normal=(0, 1, 0)):
        if isinstance(normal, torch.Tensor):
            normal = normal.cpu().numpy()

        # Align the gripper direction to the normal
        rotation_align_gripper_to_normal = self.rotation_matrix_from_vectors(gripper_normal, normal)

        # Generate a series of rotations around the Z axis
        angles_degrees = self._random_rotations()

        rotations = [Rotation.from_rotvec(normal * angle) * rotation_align_gripper_to_normal for angle in
                     angles_degrees]

        return rotations, angles_degrees

    def get_segmentation_fast(self):
        if self.mask_generator is None:
            self.loadSAM()
        self.maskmaps = []
        for i in range(len(self.colormaps)):
            masks_origin = self.mask_generator.generate(self.colormaps[i])
            if len(masks_origin) != 0:
                self.maskmaps.append(masks_origin)
            else:
                self.maskmaps.append([])

    def remove_and_wait(self, timeout=2.0):
        # wait for objects to rest while removing bodies that fell outside the workspace
        removed_object = True
        while removed_object:
            self.wait_for_objects_to_rest(timeout=timeout)
            removed_object = self.remove_objects_outside_workspace()

    def wait_for_objects_to_rest(self, timeout=2.0, tol=0.01):
        timeout = self.world.sim_time + timeout
        objects_resting = False
        while not objects_resting and self.world.sim_time < timeout:
            # simulate a quarter of a second
            for _ in range(60):
                self.world.step()
            # check whether all objects are resting
            objects_resting = True
            for _, body in self.world.bodies.items():
                if np.linalg.norm(body.get_velocity()) > tol:
                    objects_resting = False
                    break

    def remove_objects_outside_workspace(self):
        removed_object = False
        for body in list(self.world.bodies.values()):
            xyz = body.get_pose().translation
            if np.any(xyz < 0.0) or np.any(xyz > self.size):
                self.world.remove_body(body)
                removed_object = True
        return removed_object

    def check_success(self, gripper):
        # check that the fingers are in contact with some object and not fully closed
        contacts = self.world.get_contacts(gripper.body)
        res = len(contacts) > 0 and gripper.read() > 0.1 * gripper.max_opening_width
        return res

    def calculate_rectangle_vertices(self, length, width, height, tcp, quat):

        rotation_matrix = Rotation.from_quat(quat).as_matrix()

        vectors_local = [
            np.array([+width / 2, +length / 2, height]),
            np.array([-width / 2, +length / 2, height]),
            np.array([-width / 2, -length / 2, height]),
            np.array([+width / 2, -length / 2, height]),
        ]

        vertices = []
        for v in vectors_local:
            v_rotated = rotation_matrix.dot(v) + tcp
            vertices.append(v_rotated)

        return np.asarray(vertices)

    def calculate_rectangle_vertices_batch(self, length, width, height, tcp_batch, quat_batch):
        # Convert quaternion batch to rotation matrices
        rotation_matrices = Rotation.from_quat(quat_batch).as_matrix()

        # Define the local vectors for the rectangle vertices
        vectors_local = np.array([
            [+width / 2, +length / 2, height],
            [-width / 2, +length / 2, height],
            [-width / 2, -length / 2, height],
            [+width / 2, -length / 2, height]
        ])

        batch_size = tcp_batch.shape[0]

        # Repeat vectors_local for each item in the batch
        vectors_local_batch = np.tile(vectors_local, (batch_size, 1, 1))

        # Perform batch rotation and translation
        rotated_vectors = np.einsum('bij,bvj->bvi', rotation_matrices, vectors_local_batch)
        vertices_batch = rotated_vectors + tcp_batch[:, np.newaxis, :]

        return vertices_batch

    def decode_action_batch(self, actions, translation_offset=0.008, z_thresh=0.051, vertical_offset=0.007):
        orig_positions = actions[:, :3]
        rots = actions[:, 3:7]
        normal_vectors = actions[:, 7:]

        unit_normal_vectors = normal_vectors / np.linalg.norm(normal_vectors, axis=1, keepdims=True)

        translation_distance = np.full((actions.shape[0], 1), self.gripper.max_opening_width / 2 - translation_offset)
        translation_vectors = -unit_normal_vectors * translation_distance
        positions_after_translation = orig_positions + translation_vectors

        finger_positions = self.calculate_rectangle_vertices_batch(length=0.09, width=0.018, height=0.009,
                                                                   tcp_batch=positions_after_translation,
                                                                   quat_batch=rots)

        graspable_mask = np.all(finger_positions[:, :, 2] > z_thresh, axis=1)

        graspable_results = np.where(graspable_mask, 1, 0)

        # for i, graspable in enumerate(graspable_mask):
        #     if not graspable:
        #         rotation = Rotation.from_quat(rots[i])
        #         global_z_direction = rotation.apply([0, 0, 1])
        #
        #         cur_vertical_offset = -5e-4
        #         while cur_vertical_offset >= -vertical_offset:
        #             z_translation_vector = global_z_direction * cur_vertical_offset
        #             final_position = positions_after_translation[i] + z_translation_vector
        #
        #             final_finger_positions = finger_positions[i] + z_translation_vector
        #
        #             final_z = np.min(final_finger_positions[:, 2])
        #
        #             if final_z >= z_thresh:
        #                 graspable_results[i] = 1
        #                 positions_after_translation[i] = final_position
        #                 break
        #             cur_vertical_offset -= 5e-4

        return graspable_results, positions_after_translation, rots

    def _decodeAction(self, action, translation_offset=0.008, vertical_offset=0.007, z_thresh=0.051):

        orig_position, rot, normal_vector = action

        unit_normal_vector = normal_vector / np.linalg.norm(normal_vector)

        translation_distance = self.gripper.max_opening_width / 2 - translation_offset
        translation_vector = -unit_normal_vector * translation_distance
        position_after_translation = orig_position + translation_vector

        finger_positions = self.calculate_rectangle_vertices(length=0.09, width=0.018, height=0.009,
                                                             tcp=position_after_translation,
                                                             quat=rot)

        if np.all(finger_positions[:, 2] > z_thresh):
            return (1, position_after_translation, rot)

        rotation = Rotation.from_quat(rot)
        global_z_direction = rotation.apply([0, 0, 1])

        cur_vertical_offset = -5e-4
        while cur_vertical_offset >= -vertical_offset:
            z_translation_vector = global_z_direction * cur_vertical_offset
            final_position = position_after_translation + z_translation_vector

            final_finger_positions = finger_positions + z_translation_vector

            final_z = np.min(final_finger_positions[:, 2])

            if final_z >= z_thresh:
                return (1, final_position, rot)
            cur_vertical_offset -= 5e-4

        return (0, position_after_translation, rot)

    def execute_grasp(self, action, remove=False, allow_contact=True, waitTime=0):
        graspable, pos, rot_q = self._decodeAction(action)
        grasped_object_ind = None

        if graspable == 0:
            self.gripper.holding_obj = None
            self.gripper.move_home()
            result = Label.FAILURE, self.gripper.max_opening_width, 'pregrasp'
            return result, grasped_object_ind, graspable

        grasp_pose = Transform(Rotation.from_quat(rot_q), pos)

        # # Take action specified by motion primitive
        # self.panda.pick(pick_info, objects=self.world.bodies.values())
        T_world_grasp = grasp_pose
        T_grasp_pregrasp = Transform(Rotation.identity(), [0.0, 0.0, -0.05])
        T_world_pregrasp = T_world_grasp * T_grasp_pregrasp
        approach = T_world_grasp.rotation.as_matrix()[:, 2]
        angle = np.arccos(np.dot(approach, np.r_[0.0, 0.0, -1.0]))

        if angle > np.pi / 3.0:
            # side grasp, lift the object after establishing a grasp
            T_grasp_pregrasp_world = Transform(Rotation.identity(), [0.0, 0.0, 0.1])
            T_world_retreat = T_grasp_pregrasp_world * T_world_grasp
        else:
            T_grasp_retreat = Transform(Rotation.identity(), [0.0, 0.0, -0.1])
            T_world_retreat = T_world_grasp * T_grasp_retreat

        self.gripper.reset()
        self.gripper.set_tcp(T_world_pregrasp)
        self.world.step()
        if self.gripper.detect_contact():
            result = Label.FAILURE, self.gripper.max_opening_width, 'pregrasp'
            self.gripper.holding_obj = None
            self.gripper.move_home()
        else:
            self.gripper.move_tcp_xyz(T_world_grasp, abort_on_contact=False)
            if self.gripper.detect_contact() and not allow_contact:
                result = Label.FAILURE, self.gripper.max_opening_width, 'grasp'
                self.gripper.holding_obj = None
                self.gripper.move_home()
            else:
                self.gripper.move(0.0)
                self.gripper.move_tcp_xyz(T_world_retreat, abort_on_contact=False)
                self.gripper.holding_obj = self.gripper.getPickedObj()
                if self.gripper.holding_obj:
                    result = Label.SUCCESS, self.gripper.read(), 'success'
                    if remove:
                        contacts = self.world.get_contacts(self.gripper.body)
                        self.world.remove_body(contacts[0].bodyB)
                else:
                    result = Label.FAILURE, self.gripper.max_opening_width, 'after'
                self.gripper.move_home()
                self.world.step()

        if self.gripper.holding_obj is not None:
            grasped_object_ind = self.gripper.holding_obj.uid

        self.wait_for_objects_to_rest(waitTime)
        if remove:
            self.remove_and_wait()
        return result, grasped_object_ind, graspable

    def eval_single_grasp(self, index, segmentation_gt, grasp_obj_id):
        """
        validate the grasp whether success or not
        Args:
            index: the index of the grasp point in the point cloud
            segmentation_gt: the ground truth of the segmentation from the pybullet.
                             For the given pixel (x, y), get its corresponding object ID.
            grasp_obj_id: the uid of the grasping object

        Returns: whether success or not
        """
        if grasp_obj_id is None:
            return False, None
        target_object_id = segmentation_gt[index]
        if target_object_id == grasp_obj_id:
            return True, grasp_obj_id

        return False, grasp_obj_id

    def getObservation(self):
        '''get raw inbound pcds and imgs,
           the pcds have lots zero values, if you need filter later,
           please use self.pcds_rgb = self.pcds_rgb[self.non_zero_indices]'''
        self.colormaps, self.heightmaps, self.segmaps = zip(
            *[self.camera.render_camera(config) for config in self.cams_config])

        self.pcds_xyz, self.pcds_rgb, self.colormaps, self.heightmaps = utils_3d.get_inbound_imgs_and_pcd(
            self.colormaps,
            self.heightmaps,
            self.cams_config,
            self.workspace
        )
        self.non_zero_indices = ~np.all(self.pcds_xyz == 0, axis=1)

    def get_segmentation(self):
        if self.mask_generator is None:
            self.loadSAM()
        self.maskmaps = []
        self.maskrgbmaps = []
        length = self.pcds_xyz.shape[0] // 3
        for i in range(len(self.colormaps)):
            masks_origin = self.mask_generator.generate(self.colormaps[i])
            if masks_origin is not None:
                masks_filtered = filter_masks(masks_origin, self.pcds_xyz[i * length:(i + 1) * length], 0.1,
                                              bound_ratio=self.bound_radio)
                if len(masks_filtered) > 0:
                    masks_rgb = get_mask_rgb(masks_filtered)
                else:
                    masks_rgb = np.full(
                        (masks_origin[0]['segmentation'].shape[0], masks_origin[0]['segmentation'].shape[1], 3),
                        200,
                        dtype=np.uint8)
            else:
                masks_filtered = []
                masks_rgb = masks_rgb = np.full(
                    (masks_origin[0]['segmentation'].shape[0], masks_origin[0]['segmentation'].shape[1], 3),
                    200,
                    dtype=np.uint8)
            self.maskmaps += (masks_filtered,)
            self.maskrgbmaps += (masks_rgb,)

    def close(self):
        self.world.close()


class Gripper(object):
    """Simulated Panda hand."""

    def __init__(self, world):
        self.world = world
        self.urdf_path = Path(f"{os.path.abspath(os.path.dirname(__file__))}/data_robot/urdfs/panda/hand.urdf")

        self.max_opening_width = 0.08
        self.finger_depth = 0.05

        self.holding_obj = None
        self.position = np.array((0.15, 0.15, 0.6))

        self.T_body_tcp = Transform(Rotation.identity(), [0.0, 0.0, 0.0625])
        self.T_tcp_body = self.T_body_tcp.inverse()
        self.home_pose = Transform(Rotation.from_euler('x', 180, degrees=True), self.position)
        self.body = self.world.load_urdf(self.urdf_path, self.home_pose * self.T_tcp_body, scale=1.0, env_obj=True)
        self.world.p.changeDynamics(self.body.uid, 0, lateralFriction=0.75, spinningFriction=0.05)
        self.world.p.changeDynamics(self.body.uid, 1, lateralFriction=0.75, spinningFriction=0.05)

        # sets the position of the COM, not URDF link
        self.constraint = self.world.add_constraint(
            self.body,
            None,
            None,
            None,
            pybullet.JOINT_FIXED,
            [0.0, 0.0, 0.0],
            Transform.identity(),
            self.home_pose * self.T_tcp_body
        )

        # constraint to keep fingers centered
        self.world.add_constraint(
            self.body,
            self.body.links["panda_leftfinger"],
            self.body,
            self.body.links["panda_rightfinger"],
            pybullet.JOINT_GEAR,
            [1.0, 0.0, 0.0],
            Transform.identity(),
            Transform.identity(),
        ).change(gearRatio=-1, erp=0.1, maxForce=30)

        self.reset()

    def reset(self, opening_width=0.08):

        self.holding_obj = None
        self.joint1 = self.body.joints["panda_finger_joint1"]
        self.joint1.set_position(0.5 * opening_width, kinematics=True)
        self.joint2 = self.body.joints["panda_finger_joint2"]
        self.joint2.set_position(0.5 * opening_width, kinematics=True)

    def update_tcp_constraint(self, T_world_tcp):
        T_world_body = T_world_tcp * self.T_tcp_body
        self.constraint.change(
            jointChildPivot=T_world_body.translation,
            jointChildFrameOrientation=T_world_body.rotation.as_quat(),
            maxForce=300,
        )

    def set_tcp(self, T_world_tcp):
        T_word_body = T_world_tcp * self.T_tcp_body
        self.body.set_pose(T_word_body)
        self.update_tcp_constraint(T_world_tcp)

    def move_home(self):
        self.set_tcp(self.home_pose)

    def move_tcp_xyz(self, target, eef_step=0.002, vel=0.10, abort_on_contact=True):
        T_world_body = self.body.get_pose()
        T_world_tcp = T_world_body * self.T_body_tcp

        diff = target.translation - T_world_tcp.translation
        n_steps = int(np.linalg.norm(diff) / eef_step)
        dist_step = diff / n_steps
        dur_step = np.linalg.norm(dist_step) / vel

        for _ in range(n_steps):
            T_world_tcp.translation += dist_step
            self.update_tcp_constraint(T_world_tcp)
            for _ in range(int(dur_step / self.world.dt)):
                self.world.step()
            if abort_on_contact and self.detect_contact():
                return

    def detect_contact(self):
        # time.sleep(1)
        if self.world.p.getContactPoints(self.body.uid):
            return True
        else:
            return False

    def grasp_object_id(self):
        contacts = self.world.get_contacts(self.body)
        for contact in contacts:
            # contact = contacts[0]
            # get rid body
            grased_id = contact.bodyB
            if grased_id.uid != self.body.uid:
                return grased_id.uid
        return None

    def getPickedObj(self):

        for body in self.world.bodies.values():
            if body.uid == self.body.uid:
                continue
            contact_points_left = self.world.p.getContactPoints(self.body.uid, body.uid,
                                                                self.body.links["panda_leftfinger"].link_index)
            contact_points_right = self.world.p.getContactPoints(self.body.uid, body.uid,
                                                                 self.body.links["panda_rightfinger"].link_index)
            if contact_points_left and contact_points_right:
                return body

        return None

    def move(self, width):
        self.joint1.set_position(0.5 * width)
        self.joint2.set_position(0.5 * width)
        for _ in range(int(0.5 / self.world.dt)):
            self.world.step()

    def read(self):
        width = self.joint1.get_position() + self.joint2.get_position()
        return width

    def move_tcp_pose(self, target, eef_step1=0.002, vel1=0.10, abs=False):
        T_world_body = self.body.get_pose()
        T_world_tcp = T_world_body * self.T_body_tcp
        pos_diff = target.translation - T_world_tcp.translation
        n_steps = max(int(np.linalg.norm(pos_diff) / eef_step1), 10)
        dist_step = pos_diff / n_steps
        dur_step = np.linalg.norm(dist_step) / vel1
        key_rots = np.stack((T_world_body.rotation.as_quat(), target.rotation.as_quat()), axis=0)
        key_rots = Rotation.from_quat(key_rots)
        slerp = Slerp([0.0, 1.0], key_rots)
        times = np.linspace(0, 1, n_steps)
        orientations = slerp(times).as_quat()
        for ii in range(n_steps):
            T_world_tcp.translation += dist_step
            T_world_tcp.rotation = Rotation.from_quat(orientations[ii])
            if abs is True:
                # todo by haojie add the relation transformation later
                self.constraint.change(
                    jointChildPivot=T_world_tcp.translation,
                    jointChildFrameOrientation=T_world_tcp.rotation.as_quat(),
                    maxForce=300,
                )
            else:
                self.update_tcp_constraint(T_world_tcp)
            for _ in range(int(dur_step / self.world.dt)):
                self.world.step()

    def move_gripper_top_down(self):
        current_pose = self.body.get_pose()
        pos = current_pose.translation + 0.1
        flip = Rotation.from_euler('y', np.pi)
        target_ori = Rotation.identity() * flip
        self.move_tcp_pose(Transform(rotation=target_ori, translation=pos), abs=True)
